{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95834a6",
   "metadata": {},
   "source": [
    "# GET your API from Here \n",
    "- https://aistudio.google.com/app/apike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbc86ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='S. DINESH KUMAR || 2021PECAI250 \\nsvani4830@gmail.com ||+91 9342372124 ||https://github.com/SDineshKumar1304 || www.linkedin.com/in/s-dineshkumar2004  \\nPROFESSIONAL EXPERIENCE \\nINNOMATICS RESEARCH LABS                                                                                                India, Hyderabad \\nJunior Data Scientist Intern                                                                                             Jan 2024-Present (Remote) \\nML Flow Model Experimentation: \\nApplication Development: \\nExploratory Data Analysis: \\n● Developed ” Gen-AI A Multi-faceted AI Endeavor ”.Working on Gemini-1.5 pro  LLM  \\n● Utilized Chroma DB  to develop a Search Engine  using tfidf-vectorizer and Cosine similarity  model for \\nMovie Subtitles information retrieval system. \\n● Developed Real Time Sentiment Analysis on Flipkart Products reviews web application with Flask \\nDeployed the Web application on AWS \\n● Utilized ML Flow and Prefect Orchestration for model Experimentation and Model Management.  \\n● Real-time Intern Demographic Analysis: Analysed and visualized intern demographics in real-time.Data \\nRecovery and Misconduct Identification using python. \\n● Data-Driven Insights for Pizza Store Operations: Improved delivery performance and revenue management \\nthrough data analysis . \\n● EDA of AMCAT  Dataset and Hypothesis Testing: Investigated salary claims using exploratory data analysis \\nand hypothesis testing.  \\n● Regex Matching Web App Development and AWS Deployment: Created and deployed a regex matching web \\napplication on AWS  \\nRadicalX AI New York, NY \\nAI Engineer Intern NOV 2023 – Jan 2024 (Remote) \\n\\uf0b7 Constructed a Large Language Model for Prompt Parsing utilizing the GPT TURBO-3.5.  \\n\\uf0b7 Evaluated LLM responses where there isn\\'t a single \"right answer\".  \\nZigson Technologies Pvt Ltd I NDIA \\nData Analyst Intern Dec 2023 – Dec 2023 (Remote) \\n\\uf0b7 Designed a user-friendly dashboard using Power BI to analyze Global Superstore sales data.  \\n\\uf0b7 Enhanced data accuracy by building strong relationships between Attributes.  \\nTechnohacks Edutech Pvt Ltd I NDIA \\nDATA SCIENCE INTERN  Nov 2023 – Dec 2023 (Remote) \\n● Trained RandomForestClassifier with Accuracy:81.05% on Telco Customer Churn Analysis . \\n● Created an interactive real-time Analysis Web dashboard to gauge the Analysis in real time \\nEDUCATION \\nPANIMALAR ENGINEERING COLLEGE I NDIA, TN \\nBachelor of Technology in Artificial Intelligence and Data Science - grade-8.4(upto 5th Sem) 2021-2025 \\nScholastic Achievements \\n● Copyrights Certified for my 1st Software Work Idea on the Domain of Artificial Intelligence. \\n● Secured 2nd Copyrights Groundbreaking HealthCare Solution in the domain of Artificial intelligence. \\n● Hacker Rank Skill Certifications and Obtained Gold Badge for Basic of Python. \\n● Hacker Rank Skill Certification and Obtained Silver Badge for the Basics of SQL. \\n● Hacker Rank Skill Certification for Software Engineer Intern Role . \\n● Udemy Certification for Numpy, Pandas, Matplot, Scipy and Machine Learning. \\n● Attained Gold Category with 81% in NASSCOM Certification for Data Science for Beginners. \\n● Microsoft and LinkedIn\\'s Generative AI program, earned certification in Career Essentials. \\n● Secured Global Rank 164 in IEEE Extreme 17.0 coding Competition IEEE Excellence Award.  \\n● Secured Top 10% in 6-hour Hackathon by Innomatics Research Labs \\n● Excelled among 20,000+ applicants and Shortlisted for Data Science Internship Opportunity. \\nVAILANKANNI MATRIC HIGHER SECONDARY SCHOOL  INDIA,  TN \\nHigher Secondary Major in Mathematics and Biology  2020-2021 \\n● Attained 93% of Class XII, TamilNadu Board \\nVAILANKANNI MATRIC HIGHER SECONDARY SCHOOL  INDIA,  TN \\nSSLC, Major in Mathematics and Biology  2018-2019 \\n● Attained 93.3% of Class X, TamilNadu Board', metadata={'source': 'Resume.pdf', 'page': 0}),\n",
       " Document(page_content='ADDITIONAL INFORMATION \\n● Technical Skills: Python,Flask,Streamlit,SQL&DBMS,EDA,MLOPS,Machine Learning,Data \\nAnalytics,PowerBI, NLP, AWS Deployment. \\n● Languages: Fluent in Tamil (native), English, Telugu. \\nRESEARCH ENDEAVORS \\n \\nNLP \\n\\uf0b7 Created a special voice assistant that understands how users feel when they speak.  \\n\\uf0b7 Developed a special way to give personalized advice based on how the user feels.  \\n\\uf0b7 Stands out as a friendly and supportive assistant, offering a special experience unlike others.  \\nWeb Application (Mlops) \\n\\uf0b7 Collected and parsed data manually for sentiment analysis.  \\n\\uf0b7 Built Natural Language Processing Sentiment analysis model with Accuracy: 93.41%.  \\n\\uf0b7 Constructed pipeline, TF-IDF vectorization and a SVM with linear kernel for model training.  \\n\\uf0b7 Integrated the model into a Flask server for real-time predictions.  \\n\\uf0b7 Designed and implemented a visually appealing web interface using basic HTML and CSS.  \\n\\uf0b7 Implemented user registration functionality using an SQL database within the Flask application.  \\n\\uf0b7 Conducted data recollection and visualized results in Excel.  \\nWeb Application (Thirukkural Bot) \\n\\uf0b7 Involved developing Thirukkural Web application for quick detail Extraction for each Kural.  \\n\\uf0b7 Utilized Streamlit for UI Development  \\n\\uf0b7 Successfully tested the application prototype functions and results.  \\nPUBLICATIONS \\nGCITC Conference IEEEExplore (2024) (Published) \\n\\uf0b7 Presented Groundbreaking Research Paper in REVA University.  \\n\\uf0b7 Utilized advanced technology, including Mask R-CNN, Marching Cube Algorithm, voxelization and computer \\nvision technique.  \\nPEC TEAM Conference (2024 ) (Yet to be Published) \\n\\uf0b7 Contributed Research on Decision Tree Classifier for Healthcare Resource Allocation System.  \\n    PEC TEAM Conference (2023) (Yet to be Published) \\n\\uf0b7 Explored research on Trilateration Algorithm for Lost Object Tracking  \\nSOCIAL IMPACT \\n\\uf0b7 Dedicated my Commitment to Social Responsibility and to make Positive Community.  \\n\\uf0b7 Collaborated with Local Community, impacted over 70+kids by providing Supportive education and Preventive \\nEmpowerment.  \\nEXTRA-CURRICULAR ACTIVITIES \\nSports   - Cricket, chess, Carrom \\nHobbies - Playing Mobile games, listening music,Drawing .', metadata={'source': 'Resume.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"Resume.pdf\")\n",
    "data = loader.load_and_split()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0a7ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 784, which is longer than the specified 200\n",
      "Created a chunk of size 227, which is longer than the specified 200\n",
      "Created a chunk of size 280, which is longer than the specified 200\n",
      "Created a chunk of size 370, which is longer than the specified 200\n",
      "Created a chunk of size 221, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=200, chunk_overlap=200)\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "print(len(chunks))\n",
    "\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93471b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=\"YOUR_API_KEY\", \n",
    "                                               model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c587535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svani\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Embed each chunk and load it into the vector store\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# Persist the database on drive\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7248f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9cf2fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b6cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'Explain this Resume'\n",
    "retrieved_docs = retriever.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e876b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDITIONAL INFORMATION \n",
      "● Technical Skills: Python,Flask,Streamlit,SQL&DBMS,EDA,MLOPS,Machine Learning,Data \n",
      "Analytics,PowerBI, NLP, AWS Deployment.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa62d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # System Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a Helpful AI Bot. \n",
    "    You take the context and question from user. Your answer should be based on the specific context.\"\"\"),\n",
    "    # Human Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ce6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7904619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4c3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"YOUR_API_KEY\", \n",
    "                                   model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab5fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c0ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b195a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Potential Job Roles Based on Your Skills:\\n\\nGiven your technical skills in Python, Flask, Streamlit, SQL & DBMS, EDA, MLOPS, Machine Learning, Data Analytics, PowerBI, NLP, and AWS Deployment, you have a strong foundation for several exciting job roles:\\n\\n**Data Science & Machine Learning:**\\n\\n* **Data Scientist:** Analyze large datasets, build and deploy machine learning models, and derive insights to solve business problems.\\n* **Machine Learning Engineer:** Focus on the development and deployment of machine learning models, including model optimization and scaling.\\n* **NLP Engineer:** Develop natural language processing applications, such as chatbots, text summarization tools, and sentiment analysis systems.\\n\\n**Data Analytics & Business Intelligence:**\\n\\n* **Data Analyst:** Collect, clean, and analyze data to identify trends, patterns, and insights, and create reports and visualizations to communicate findings.\\n* **Business Intelligence Analyst:** Develop and maintain BI dashboards and reports, using tools like PowerBI, to track key performance indicators and support data-driven decision making.\\n\\n**Software Development & MLOps:**\\n\\n* **Backend Developer:** Build and maintain the server-side logic of web applications using Python and Flask.\\n* **MLOps Engineer:** Design and implement MLOps pipelines to automate the machine learning model lifecycle, ensuring efficient and reliable model deployment.\\n\\n**Additional Potential Roles:**\\n\\n* **Research Scientist:** Conduct research in areas like machine learning, NLP, or artificial intelligence, and contribute to the advancement of the field.\\n* **Data Engineer:** Design, build, and maintain data infrastructure, including data pipelines and databases, to support data-driven applications.\\n\\n**Choosing the Right Path:**\\n\\n* **Interests:** Consider which areas within data science, machine learning, and analytics you find most engaging.\\n* **Experience:** Leverage your existing experience and skills to identify roles that best align with your background.\\n* **Industry:** Explore different industries, such as technology, finance, healthcare, or e-commerce, to find one that interests you.\\n\\n**Further Development:**\\n\\n* **Stay updated:** Continuously learn and adapt to new technologies and trends in the field.\\n* **Build a portfolio:** Showcase your skills and projects through a portfolio website or GitHub repository.\\n* **Network:** Connect with professionals in your desired field to learn about job opportunities and industry insights.\\n\\nI hope this information helps! Let me know if you have any further questions. \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Can you tell me about job?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91514611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Potential Job Roles Based on Your Skills:\n",
       "\n",
       "Given your technical skills in Python, Flask, Streamlit, SQL & DBMS, EDA, MLOPS, Machine Learning, Data Analytics, PowerBI, NLP, and AWS Deployment, you have a strong foundation for several exciting job roles:\n",
       "\n",
       "**Data Science & Machine Learning:**\n",
       "\n",
       "* **Data Scientist:** Analyze large datasets, build and deploy machine learning models, and derive insights to solve business problems.\n",
       "* **Machine Learning Engineer:** Focus on the development and deployment of machine learning models, including model optimization and scaling.\n",
       "* **NLP Engineer:** Develop natural language processing applications, such as chatbots, text summarization tools, and sentiment analysis systems.\n",
       "\n",
       "**Data Analytics & Business Intelligence:**\n",
       "\n",
       "* **Data Analyst:** Collect, clean, and analyze data to identify trends, patterns, and insights, and create reports and visualizations to communicate findings.\n",
       "* **Business Intelligence Analyst:** Develop and maintain BI dashboards and reports, using tools like PowerBI, to track key performance indicators and support data-driven decision making.\n",
       "\n",
       "**Software Development & MLOps:**\n",
       "\n",
       "* **Backend Developer:** Build and maintain the server-side logic of web applications using Python and Flask.\n",
       "* **MLOps Engineer:** Design and implement MLOps pipelines to automate the machine learning model lifecycle, ensuring efficient and reliable model deployment.\n",
       "\n",
       "**Additional Potential Roles:**\n",
       "\n",
       "* **Research Scientist:** Conduct research in areas like machine learning, NLP, or artificial intelligence, and contribute to the advancement of the field.\n",
       "* **Data Engineer:** Design, build, and maintain data infrastructure, including data pipelines and databases, to support data-driven applications.\n",
       "\n",
       "**Choosing the Right Path:**\n",
       "\n",
       "* **Interests:** Consider which areas within data science, machine learning, and analytics you find most engaging.\n",
       "* **Experience:** Leverage your existing experience and skills to identify roles that best align with your background.\n",
       "* **Industry:** Explore different industries, such as technology, finance, healthcare, or e-commerce, to find one that interests you.\n",
       "\n",
       "**Further Development:**\n",
       "\n",
       "* **Stay updated:** Continuously learn and adapt to new technologies and trends in the field.\n",
       "* **Build a portfolio:** Showcase your skills and projects through a portfolio website or GitHub repository.\n",
       "* **Network:** Connect with professionals in your desired field to learn about job opportunities and industry insights.\n",
       "\n",
       "I hope this information helps! Let me know if you have any further questions. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361361ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
