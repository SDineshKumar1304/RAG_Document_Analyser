{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95834a6",
   "metadata": {},
   "source": [
    "# GET your API from Here \n",
    "- https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bbc86ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='S. DINESH KUMAR || 2021PECAI250 \\nsvani4830@gmail.com ||+91 9342372124 ||https://github.com/SDineshKumar1304 || www.linkedin.com/in/s-dineshkumar2004  \\nPROFESSIONAL EXPERIENCE \\nINNOMATICS RESEARCH LABS                                                                                                India, Hyderabad \\nJunior Data Scientist Intern                                                                                             Jan 2024-Present (Remote) \\nML Flow Model Experimentation: \\nApplication Development: \\nExploratory Data Analysis: \\n● Developed ” Gen-AI A Multi-faceted AI Endeavor ”.Working on Gemini-1.5 pro  LLM  \\n● Utilized Chroma DB  to develop a Search Engine  using tfidf-vectorizer and Cosine similarity  model for \\nMovie Subtitles information retrieval system. \\n● Developed Real Time Sentiment Analysis on Flipkart Products reviews web application with Flask \\nDeployed the Web application on AWS \\n● Utilized ML Flow and Prefect Orchestration for model Experimentation and Model Management.  \\n● Real-time Intern Demographic Analysis: Analysed and visualized intern demographics in real-time.Data \\nRecovery and Misconduct Identification using python. \\n● Data-Driven Insights for Pizza Store Operations: Improved delivery performance and revenue management \\nthrough data analysis . \\n● EDA of AMCAT  Dataset and Hypothesis Testing: Investigated salary claims using exploratory data analysis \\nand hypothesis testing.  \\n● Regex Matching Web App Development and AWS Deployment: Created and deployed a regex matching web \\napplication on AWS  \\nRadicalX AI New York, NY \\nAI Engineer Intern NOV 2023 – Jan 2024 (Remote) \\n\\uf0b7 Constructed a Large Language Model for Prompt Parsing utilizing the GPT TURBO-3.5.  \\n\\uf0b7 Evaluated LLM responses where there isn\\'t a single \"right answer\".  \\nZigson Technologies Pvt Ltd I NDIA \\nData Analyst Intern Dec 2023 – Dec 2023 (Remote) \\n\\uf0b7 Designed a user-friendly dashboard using Power BI to analyze Global Superstore sales data.  \\n\\uf0b7 Enhanced data accuracy by building strong relationships between Attributes.  \\nTechnohacks Edutech Pvt Ltd I NDIA \\nDATA SCIENCE INTERN  Nov 2023 – Dec 2023 (Remote) \\n● Trained RandomForestClassifier with Accuracy:81.05% on Telco Customer Churn Analysis . \\n● Created an interactive real-time Analysis Web dashboard to gauge the Analysis in real time \\nEDUCATION \\nPANIMALAR ENGINEERING COLLEGE I NDIA, TN \\nBachelor of Technology in Artificial Intelligence and Data Science - grade-8.4(upto 5th Sem) 2021-2025 \\nScholastic Achievements \\n● Copyrights Certified for my 1st Software Work Idea on the Domain of Artificial Intelligence. \\n● Secured 2nd Copyrights Groundbreaking HealthCare Solution in the domain of Artificial intelligence. \\n● Hacker Rank Skill Certifications and Obtained Gold Badge for Basic of Python. \\n● Hacker Rank Skill Certification and Obtained Silver Badge for the Basics of SQL. \\n● Hacker Rank Skill Certification for Software Engineer Intern Role . \\n● Udemy Certification for Numpy, Pandas, Matplot, Scipy and Machine Learning. \\n● Attained Gold Category with 81% in NASSCOM Certification for Data Science for Beginners. \\n● Microsoft and LinkedIn\\'s Generative AI program, earned certification in Career Essentials. \\n● Secured Global Rank 164 in IEEE Extreme 17.0 coding Competition IEEE Excellence Award.  \\n● Secured Top 10% in 6-hour Hackathon by Innomatics Research Labs \\n● Excelled among 20,000+ applicants and Shortlisted for Data Science Internship Opportunity. \\nVAILANKANNI MATRIC HIGHER SECONDARY SCHOOL  INDIA,  TN \\nHigher Secondary Major in Mathematics and Biology  2020-2021 \\n● Attained 93% of Class XII, TamilNadu Board \\nVAILANKANNI MATRIC HIGHER SECONDARY SCHOOL  INDIA,  TN \\nSSLC, Major in Mathematics and Biology  2018-2019 \\n● Attained 93.3% of Class X, TamilNadu Board', metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}),\n",
       " Document(page_content='ADDITIONAL INFORMATION \\n● Technical Skills: Python,Flask,Streamlit,SQL&DBMS,EDA,MLOPS,Machine Learning,Data \\nAnalytics,PowerBI, NLP, AWS Deployment. \\n● Languages: Fluent in Tamil (native), English, Telugu. \\nRESEARCH ENDEAVORS \\n \\nNLP \\n\\uf0b7 Created a special voice assistant that understands how users feel when they speak.  \\n\\uf0b7 Developed a special way to give personalized advice based on how the user feels.  \\n\\uf0b7 Stands out as a friendly and supportive assistant, offering a special experience unlike others.  \\nWeb Application (Mlops) \\n\\uf0b7 Collected and parsed data manually for sentiment analysis.  \\n\\uf0b7 Built Natural Language Processing Sentiment analysis model with Accuracy: 93.41%.  \\n\\uf0b7 Constructed pipeline, TF-IDF vectorization and a SVM with linear kernel for model training.  \\n\\uf0b7 Integrated the model into a Flask server for real-time predictions.  \\n\\uf0b7 Designed and implemented a visually appealing web interface using basic HTML and CSS.  \\n\\uf0b7 Implemented user registration functionality using an SQL database within the Flask application.  \\n\\uf0b7 Conducted data recollection and visualized results in Excel.  \\nWeb Application (Thirukkural Bot) \\n\\uf0b7 Involved developing Thirukkural Web application for quick detail Extraction for each Kural.  \\n\\uf0b7 Utilized Streamlit for UI Development  \\n\\uf0b7 Successfully tested the application prototype functions and results.  \\nPUBLICATIONS \\nGCITC Conference IEEEExplore (2024) (Published) \\n\\uf0b7 Presented Groundbreaking Research Paper in REVA University.  \\n\\uf0b7 Utilized advanced technology, including Mask R-CNN, Marching Cube Algorithm, voxelization and computer \\nvision technique.  \\nPEC TEAM Conference (2024 ) (Yet to be Published) \\n\\uf0b7 Contributed Research on Decision Tree Classifier for Healthcare Resource Allocation System.  \\n    PEC TEAM Conference (2023) (Yet to be Published) \\n\\uf0b7 Explored research on Trilateration Algorithm for Lost Object Tracking  \\nSOCIAL IMPACT \\n\\uf0b7 Dedicated my Commitment to Social Responsibility and to make Positive Community.  \\n\\uf0b7 Collaborated with Local Community, impacted over 70+kids by providing Supportive education and Preventive \\nEmpowerment.  \\nEXTRA-CURRICULAR ACTIVITIES \\nSports   - Cricket, chess, Carrom \\nHobbies - Playing Mobile games, listening music,Drawing .', metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Resume.pdf\")\n",
    "data = loader.load_and_split()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d0a7ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 784, which is longer than the specified 200\n",
      "Created a chunk of size 227, which is longer than the specified 200\n",
      "Created a chunk of size 280, which is longer than the specified 200\n",
      "Created a chunk of size 370, which is longer than the specified 200\n",
      "Created a chunk of size 221, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=200, chunk_overlap=200)\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4726ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='S. DINESH KUMAR || 2021PECAI250 \\nsvani4830@gmail.com ||+91 9342372124 ||https://github.com/SDineshKumar1304 || www.linkedin.com/in/s-dineshkumar2004  \\nPROFESSIONAL EXPERIENCE \\nINNOMATICS RESEARCH LABS                                                                                                India, Hyderabad \\nJunior Data Scientist Intern                                                                                             Jan 2024-Present (Remote) \\nML Flow Model Experimentation: \\nApplication Development: \\nExploratory Data Analysis: \\n● Developed ” Gen-AI A Multi-faceted AI Endeavor ”.Working on Gemini-1.5 pro  LLM  \\n● Utilized Chroma DB  to develop a Search Engine  using tfidf-vectorizer and Cosine similarity  model for \\nMovie Subtitles information retrieval system.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Developed Real Time Sentiment Analysis on Flipkart Products reviews web application with Flask \\nDeployed the Web application on AWS \\n● Utilized ML Flow and Prefect Orchestration for model Experimentation and Model Management.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Real-time Intern Demographic Analysis: Analysed and visualized intern demographics in real-time.Data \\nRecovery and Misconduct Identification using python.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Data-Driven Insights for Pizza Store Operations: Improved delivery performance and revenue management \\nthrough data analysis .' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● EDA of AMCAT  Dataset and Hypothesis Testing: Investigated salary claims using exploratory data analysis \\nand hypothesis testing.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Regex Matching Web App Development and AWS Deployment: Created and deployed a regex matching web \\napplication on AWS  \\nRadicalX AI New York, NY \\nAI Engineer Intern NOV 2023 – Jan 2024 (Remote) \\n\\uf0b7 Constructed a Large Language Model for Prompt Parsing utilizing the GPT TURBO-3.5.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='\\uf0b7 Evaluated LLM responses where there isn\\'t a single \"right answer\".' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='Zigson Technologies Pvt Ltd I NDIA \\nData Analyst Intern Dec 2023 – Dec 2023 (Remote) \\n\\uf0b7 Designed a user-friendly dashboard using Power BI to analyze Global Superstore sales data.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='\\uf0b7 Enhanced data accuracy by building strong relationships between Attributes.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='Technohacks Edutech Pvt Ltd I NDIA \\nDATA SCIENCE INTERN  Nov 2023 – Dec 2023 (Remote) \\n● Trained RandomForestClassifier with Accuracy:81.05% on Telco Customer Churn Analysis .' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Created an interactive real-time Analysis Web dashboard to gauge the Analysis in real time \\nEDUCATION \\nPANIMALAR ENGINEERING COLLEGE I NDIA, TN \\nBachelor of Technology in Artificial Intelligence and Data Science - grade-8.4(upto 5th Sem) 2021-2025 \\nScholastic Achievements \\n● Copyrights Certified for my 1st Software Work Idea on the Domain of Artificial Intelligence.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Secured 2nd Copyrights Groundbreaking HealthCare Solution in the domain of Artificial intelligence.\\n\\n● Hacker Rank Skill Certifications and Obtained Gold Badge for Basic of Python.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Hacker Rank Skill Certifications and Obtained Gold Badge for Basic of Python.\\n\\n● Hacker Rank Skill Certification and Obtained Silver Badge for the Basics of SQL.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Hacker Rank Skill Certification and Obtained Silver Badge for the Basics of SQL.\\n\\n● Hacker Rank Skill Certification for Software Engineer Intern Role .' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Hacker Rank Skill Certification for Software Engineer Intern Role .\\n\\n● Udemy Certification for Numpy, Pandas, Matplot, Scipy and Machine Learning.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Udemy Certification for Numpy, Pandas, Matplot, Scipy and Machine Learning.\\n\\n● Attained Gold Category with 81% in NASSCOM Certification for Data Science for Beginners.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content=\"● Attained Gold Category with 81% in NASSCOM Certification for Data Science for Beginners.\\n\\n● Microsoft and LinkedIn's Generative AI program, earned certification in Career Essentials.\" metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content=\"● Microsoft and LinkedIn's Generative AI program, earned certification in Career Essentials.\\n\\n● Secured Global Rank 164 in IEEE Extreme 17.0 coding Competition IEEE Excellence Award.\" metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='● Secured Top 10% in 6-hour Hackathon by Innomatics Research Labs \\n● Excelled among 20,000+ applicants and Shortlisted for Data Science Internship Opportunity.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='VAILANKANNI MATRIC HIGHER SECONDARY SCHOOL  INDIA,  TN \\nHigher Secondary Major in Mathematics and Biology  2020-2021 \\n● Attained 93% of Class XII, TamilNadu Board \\nVAILANKANNI MATRIC HIGHER SECONDARY SCHOOL  INDIA,  TN \\nSSLC, Major in Mathematics and Biology  2018-2019 \\n● Attained 93.3% of Class X, TamilNadu Board' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 0}\n",
      "page_content='ADDITIONAL INFORMATION \\n● Technical Skills: Python,Flask,Streamlit,SQL&DBMS,EDA,MLOPS,Machine Learning,Data \\nAnalytics,PowerBI, NLP, AWS Deployment.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='● Languages: Fluent in Tamil (native), English, Telugu.\\n\\nRESEARCH ENDEAVORS \\n \\nNLP \\n\\uf0b7 Created a special voice assistant that understands how users feel when they speak.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='RESEARCH ENDEAVORS \\n \\nNLP \\n\\uf0b7 Created a special voice assistant that understands how users feel when they speak.\\n\\n\\uf0b7 Developed a special way to give personalized advice based on how the user feels.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Developed a special way to give personalized advice based on how the user feels.\\n\\n\\uf0b7 Stands out as a friendly and supportive assistant, offering a special experience unlike others.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Stands out as a friendly and supportive assistant, offering a special experience unlike others.\\n\\nWeb Application (Mlops) \\n\\uf0b7 Collected and parsed data manually for sentiment analysis.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='Web Application (Mlops) \\n\\uf0b7 Collected and parsed data manually for sentiment analysis.\\n\\n\\uf0b7 Built Natural Language Processing Sentiment analysis model with Accuracy: 93.41%.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Built Natural Language Processing Sentiment analysis model with Accuracy: 93.41%.\\n\\n\\uf0b7 Constructed pipeline, TF-IDF vectorization and a SVM with linear kernel for model training.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Constructed pipeline, TF-IDF vectorization and a SVM with linear kernel for model training.\\n\\n\\uf0b7 Integrated the model into a Flask server for real-time predictions.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Integrated the model into a Flask server for real-time predictions.\\n\\n\\uf0b7 Designed and implemented a visually appealing web interface using basic HTML and CSS.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Designed and implemented a visually appealing web interface using basic HTML and CSS.\\n\\n\\uf0b7 Implemented user registration functionality using an SQL database within the Flask application.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Implemented user registration functionality using an SQL database within the Flask application.\\n\\n\\uf0b7 Conducted data recollection and visualized results in Excel.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Conducted data recollection and visualized results in Excel.\\n\\nWeb Application (Thirukkural Bot) \\n\\uf0b7 Involved developing Thirukkural Web application for quick detail Extraction for each Kural.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Utilized Streamlit for UI Development  \\n\\uf0b7 Successfully tested the application prototype functions and results.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='PUBLICATIONS \\nGCITC Conference IEEEExplore (2024) (Published) \\n\\uf0b7 Presented Groundbreaking Research Paper in REVA University.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Utilized advanced technology, including Mask R-CNN, Marching Cube Algorithm, voxelization and computer \\nvision technique.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='PEC TEAM Conference (2024 ) (Yet to be Published) \\n\\uf0b7 Contributed Research on Decision Tree Classifier for Healthcare Resource Allocation System.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='PEC TEAM Conference (2023) (Yet to be Published) \\n\\uf0b7 Explored research on Trilateration Algorithm for Lost Object Tracking  \\nSOCIAL IMPACT \\n\\uf0b7 Dedicated my Commitment to Social Responsibility and to make Positive Community.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='\\uf0b7 Collaborated with Local Community, impacted over 70+kids by providing Supportive education and Preventive \\nEmpowerment.' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n",
      "page_content='EXTRA-CURRICULAR ACTIVITIES \\nSports   - Cricket, chess, Carrom \\nHobbies - Playing Mobile games, listening music,Drawing .' metadata={'source': 'C:\\\\Users\\\\svani\\\\RAG\\\\Resume.pdf', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35cf21db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab45b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93471b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=\"YOUR_API_KEY\", \n",
    "                                               model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c587535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svani\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Embed each chunk and load it into the vector store\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# Persist the database on drive\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7248f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9cf2fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b6cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'Explain this Resume'\n",
    "retrieved_docs = retriever.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e876b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDITIONAL INFORMATION \n",
      "● Technical Skills: Python,Flask,Streamlit,SQL&DBMS,EDA,MLOPS,Machine Learning,Data \n",
      "Analytics,PowerBI, NLP, AWS Deployment.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa62d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # System Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a Helpful AI Bot. \n",
    "    You take the context and question from user. Your answer should be based on the specific context.\"\"\"),\n",
    "    # Human Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Aswer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ce6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7904619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f4c3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"YOUR_API_KEY\", \n",
    "                                   model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ab5fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04c0ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45b195a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Understanding Your Potential Job Roles Based on Your Skills\\n\\nGiven your listed technical skills, you seem well-equipped for a variety of exciting roles in the data science and software development fields. Let's explore some potential job titles and what they might entail:\\n\\n**Data Science & Machine Learning:**\\n\\n* **Machine Learning Engineer:** You would be responsible for designing, building, and deploying machine learning models to solve real-world problems. Your skills in Python, ML, EDA, and MLOps would be crucial here.\\n* **Data Scientist:** Analyzing large datasets, extracting insights, and communicating findings to stakeholders would be your core responsibility. Expertise in EDA, Machine Learning, PowerBI, and SQL would be essential.\\n* **NLP Engineer:**  You would focus on developing systems that can understand and process human language. Your NLP and Python skills would be invaluable in this role.\\n\\n**Software Development & Deployment:**\\n\\n* **Backend Developer:** Building and maintaining the server-side logic of web applications would be your primary focus. Python, Flask, and SQL knowledge would be key.\\n* **Full-Stack Developer:** You would work on both the front-end and back-end of web applications, requiring proficiency in Python, Flask, and potentially JavaScript frameworks.\\n* **Cloud Engineer/DevOps Engineer:**  Your understanding of AWS deployment would be valuable for managing and deploying applications on cloud platforms.\\n\\n**Data Analysis & Business Intelligence:**\\n\\n* **Data Analyst:** You would gather, clean, and interpret data to answer business questions and support decision-making. Skills in SQL, PowerBI, and data analytics would be essential.\\n* **Business Intelligence Analyst:**  You would design and develop dashboards and reports to visualize data and track key performance indicators. Expertise in PowerBI and data analysis would be crucial.\\n\\n**Additional Factors to Consider:**\\n\\n* **Industry:** Your specific skills may be more relevant in certain industries than others. For example, NLP has applications in healthcare, finance, and customer service.\\n* **Experience Level:** Entry-level positions may focus on specific tasks, while senior roles often involve more leadership and strategic responsibilities.\\n* **Company Size and Culture:** Startups might offer more diverse responsibilities, while larger companies could provide structured career paths and mentorship.\\n\\n**Exploring Job Opportunities:**\\n\\n* **Job Boards:** Explore platforms like LinkedIn, Indeed, Glassdoor, and AngelList to discover relevant openings.\\n* **Networking:** Attend industry events, connect with professionals on LinkedIn, and reach out to your network for potential leads.\\n* **Company Websites:**  Check the career pages of companies you're interested in for open positions.\\n\\n**Remember, this is not an exhaustive list, and your ideal job will depend on your interests, career goals, and experience.** \\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Can you tell me about job?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91514611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Understanding Your Potential Job Roles Based on Your Skills\n",
       "\n",
       "Given your listed technical skills, you seem well-equipped for a variety of exciting roles in the data science and software development fields. Let's explore some potential job titles and what they might entail:\n",
       "\n",
       "**Data Science & Machine Learning:**\n",
       "\n",
       "* **Machine Learning Engineer:** You would be responsible for designing, building, and deploying machine learning models to solve real-world problems. Your skills in Python, ML, EDA, and MLOps would be crucial here.\n",
       "* **Data Scientist:** Analyzing large datasets, extracting insights, and communicating findings to stakeholders would be your core responsibility. Expertise in EDA, Machine Learning, PowerBI, and SQL would be essential.\n",
       "* **NLP Engineer:**  You would focus on developing systems that can understand and process human language. Your NLP and Python skills would be invaluable in this role.\n",
       "\n",
       "**Software Development & Deployment:**\n",
       "\n",
       "* **Backend Developer:** Building and maintaining the server-side logic of web applications would be your primary focus. Python, Flask, and SQL knowledge would be key.\n",
       "* **Full-Stack Developer:** You would work on both the front-end and back-end of web applications, requiring proficiency in Python, Flask, and potentially JavaScript frameworks.\n",
       "* **Cloud Engineer/DevOps Engineer:**  Your understanding of AWS deployment would be valuable for managing and deploying applications on cloud platforms.\n",
       "\n",
       "**Data Analysis & Business Intelligence:**\n",
       "\n",
       "* **Data Analyst:** You would gather, clean, and interpret data to answer business questions and support decision-making. Skills in SQL, PowerBI, and data analytics would be essential.\n",
       "* **Business Intelligence Analyst:**  You would design and develop dashboards and reports to visualize data and track key performance indicators. Expertise in PowerBI and data analysis would be crucial.\n",
       "\n",
       "**Additional Factors to Consider:**\n",
       "\n",
       "* **Industry:** Your specific skills may be more relevant in certain industries than others. For example, NLP has applications in healthcare, finance, and customer service.\n",
       "* **Experience Level:** Entry-level positions may focus on specific tasks, while senior roles often involve more leadership and strategic responsibilities.\n",
       "* **Company Size and Culture:** Startups might offer more diverse responsibilities, while larger companies could provide structured career paths and mentorship.\n",
       "\n",
       "**Exploring Job Opportunities:**\n",
       "\n",
       "* **Job Boards:** Explore platforms like LinkedIn, Indeed, Glassdoor, and AngelList to discover relevant openings.\n",
       "* **Networking:** Attend industry events, connect with professionals on LinkedIn, and reach out to your network for potential leads.\n",
       "* **Company Websites:**  Check the career pages of companies you're interested in for open positions.\n",
       "\n",
       "**Remember, this is not an exhaustive list, and your ideal job will depend on your interests, career goals, and experience.** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361361ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
